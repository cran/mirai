<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="generator" content="litedown 0.5">
<title>mirai - Minimalist Async Evaluation Framework for R</title>
<style type="text/css">
body {
  font-family: sans-serif;
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 1.5;
}
body, .abstract, code, .footnotes, footer, #refs, .caption { font-size: .9em; }
li li { font-size: .95em; }
ul:has(li > input[type="checkbox"]) { list-style: none; padding-left: 1em; }
*, :before, :after { box-sizing: border-box; }
a { color: steelblue; }
pre, img { max-width: 100%; }
pre { white-space: pre-wrap; word-break: break-word; }
pre code { display: block; padding: 1em; overflow-x: auto; }
code { font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace; }
:not(pre) > code, code[class], div > .caption { background-color: #f8f8f8; }
pre > code:is(:not([class]), .language-plain, .language-none), .box, .figure, .table { background-color: inherit; border: 1px solid #eee; }
pre > code {
  &.message { border-color: #9eeaf9; }
  &.warning { background: #fff3cd; border-color: #fff3cd; }
  &.error { background: #f8d7da; border-color: #f8d7da; }
}
.fenced-chunk { border-left: 1px solid #666; }
.code-fence {
  opacity: .4;
  border: 1px dashed #666;
  border-left: 2px solid;
  &:hover { opacity: inherit; }
}
.box, .figure, .table, table { margin: 1em auto; }
div > .caption { padding: 1px 1em; }
.figure { p:has(img), pre:has(svg) { text-align: center; } }
.flex-col { display: flex; justify-content: space-between; }
table {
  border-top: 1px solid #666;
  thead th { border-bottom: 1px solid #ddd; }
  th, td { padding: 5px; font-variant-numeric: tabular-nums; }
  thead, tfoot, tr:nth-child(even) { background: whitesmoke; }
}
blockquote {
  color: #666;
  margin: 0;
  padding: 1px 1em;
  border-left: .5em solid #eee;
}
hr, .footnotes::before { border: 1px dashed #ddd; }
.frontmatter { text-align: center; }
#TOC {
  a { text-decoration: none; }
  & > ul { padding: 0; }
  ul { list-style: none; padding-left: 1em; }
  ul ul { border-left: 1px solid lightsteelblue; }
}
table, .body h2 { border-bottom: 1px solid #666; }
.body .appendix, .appendix ~ h2 { border-bottom-style: dashed; }
.main-number::after { content: "."; }
span[class^="ref-number-"] { font-weight: bold; }
.ref-number-fig::after, .ref-number-tab::after { content: ":"; }
.cross-ref-chp::before { content: "Chapter "; }
.cross-ref-sec::before { content: "Section "; }
.cross-ref-fig::before, .ref-number-fig::before { content: "Figure "; }
.cross-ref-tab::before, .ref-number-tab::before { content: "Table "; }
.cross-ref-eqn::before, .MathJax_ref:has(mjx-mtext > mjx-c + mjx-c)::before { content: "Equation "; }
.abstract, #refs {
  &::before { display: block; margin: 1em auto; font-weight: bold; }
}
.abstract::before { content: "Abstract"; text-align: center; }
#refs::before { content: "Bibliography"; font-size: 1.5em; }
.ref-paren-open::before { content: "("; }
.ref-paren-close::after { content: ")"; }
.ref-semicolon::after { content: "; "; }
.ref-and::after { content: " and "; }
.ref-et-al::after { content: " et al."; font-style: italic; }
.footnote-ref a {
  &::before { content: "["; }
  &::after { content: "]"; }
}
section.footnotes {
  margin-top: 2em;
  &::before { content: ""; display: block; max-width: 20em; }
}
.fade {
  background: repeating-linear-gradient(135deg, white, white 30px, #ddd 32px, #ddd 32px);
  opacity: 0.6;
}

@media print {
  body { max-width: 100%; }
  tr, img { page-break-inside: avoid; }
}
@media only screen and (min-width: 992px) {
  body:not(.pagesjs) pre:has(.line-numbers):not(:hover) { white-space: pre; }
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@xiee/utils@1.13.61/css/prism-xcode.min.css">
</head>
<body>
<div class="frontmatter">
<div class="title"><h1>mirai - Minimalist Async Evaluation Framework for R</h1></div>
</div>
<div class="body">
<h3 id="sec:table-of-contents">Table of Contents</h3>
<ol>
<li><a href="#example-1-compute-intensive-operations">Example 1: Compute-intensive Operations</a></li>
<li><a href="#example-2-io-bound-operations">Example 2: I/O-bound Operations</a></li>
<li><a href="#example-3-resilient-pipelines">Example 3: Resilient Pipelines</a></li>
<li><a href="#daemons-local-persistent-processes">Daemons: Local Persistent Processes</a></li>
<li><a href="#distributed-computing-remote-daemons">Distributed Computing: Remote Daemons</a></li>
<li><a href="#distributed-computing-launching-daemons">Distributed Computing: Launching Daemons</a></li>
<li><a href="#distributed-computing-tls-secure-connections">Distributed Computing: TLS Secure Connections</a></li>
<li><a href="#compute-profiles">Compute Profiles</a></li>
<li><a href="#errors-interrupts-and-timeouts">Errors, Interrupts and Timeouts</a></li>
<li><a href="#serialization-arrow-polars-and-beyond">Serialization - Arrow, polars and beyond</a></li>
<li><a href="#asynchronous-parallel-map">Asynchronous Parallel Map</a></li>
<li><a href="#using-mirai-in-a-package">Using mirai in a Package</a></li>
</ol>
<h3 id="sec:example-1-compute-intensive-operations">Example 1: Compute-intensive Operations</h3>
<p>Use case: minimise execution times by performing long-running tasks concurrently in separate processes.</p>
<p>Multiple long computes (model fits etc.) can be performed in parallel on available computing cores.</p>
<p>Use <code>mirai()</code> to evaluate an expression asynchronously in a separate, clean R process.</p>
<p>The following mimics an expensive calculation that eventually returns a random value.</p>
<pre><code class="language-r">library(mirai)

x &lt;- list(time = 2L, mean = 4)

m &lt;- mirai({Sys.sleep(time); rnorm(5L, mean)}, time = x$time, mean = x$mean)
</code></pre>
<p>The mirai expression is evaluated in another process and hence must be self-contained, not referring to variables that do not already exist there. Above, the variables <code>time</code> and <code>mean</code> are passed as part of the <code>mirai()</code> call.</p>
<p>A ‘mirai’ object is returned immediately - creating a mirai never blocks the session.</p>
<p>Whilst the async operation is ongoing, attempting to access a mirai’s data yields an ‘unresolved’ logical NA.</p>
<pre><code class="language-r">m
#&gt; &lt; mirai [] &gt;
m$data
#&gt; 'unresolved' logi NA
</code></pre>
<p>To check whether a mirai remains unresolved (yet to complete):</p>
<pre><code class="language-r">unresolved(m)
#&gt; [1] TRUE
</code></pre>
<p>To wait for and collect the return value, use the mirai’s <code>[]</code> method:</p>
<pre><code class="language-r">m[]
#&gt; [1] 3.081159 5.130453 3.361243 3.899214 3.578723
</code></pre>
<p>As a mirai represents an async operation, it is never necessary to wait for it. Other code can continue to be run. Once it completes, the return value automatically becomes available at <code>$data</code>.</p>
<pre><code class="language-r">m
#&gt; &lt; mirai [$data] &gt;
m$data
#&gt; [1] 3.081159 5.130453 3.361243 3.899214 3.578723
</code></pre>
<p>For easy programmatic use of <code>mirai()</code>, ‘.expr’ accepts a pre-constructed language object, and also a list of named arguments passed via ‘.args’. So, the following would be equivalent to the above:</p>
<pre><code class="language-r">expr &lt;- quote({Sys.sleep(time); rnorm(5L, mean)})

args &lt;- list(time = x$time, mean = x$mean)

m &lt;- mirai(.expr = expr, .args = args)
m[]
#&gt; [1] 4.066422 2.925708 3.895417 3.189227 4.322313
</code></pre>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:example-2-i-o-bound-operations">Example 2: I/O-bound Operations</h3>
<p>Use case: ensure execution flow of the main process is not blocked.</p>
<p>High-frequency real-time data cannot be written to file/database synchronously without disrupting the execution flow.</p>
<p>Cache data in memory and use <code>mirai()</code> to perform periodic write operations concurrently in a separate process.</p>
<p>Below, ‘.args’ is used to pass <code>environment()</code>, which is the calling environment. This provides a convenient method of passing in existing objects.</p>
<pre><code class="language-r">library(mirai)

x &lt;- rnorm(1e6)
file &lt;- tempfile()

m &lt;- mirai(write.csv(x, file = file), .args = environment())
</code></pre>
<p>A ‘mirai’ object is returned immediately.</p>
<p><code>unresolved()</code> may be used in control flow statements to perform actions which depend on resolution of the ‘mirai’, both before and after.</p>
<p>This means there is no need to actually wait (block) for a ‘mirai’ to resolve, as the example below demonstrates.</p>
<pre><code class="language-r"># unresolved() queries for resolution itself so no need to use it again within the while loop
while (unresolved(m)) {
  cat(&quot;while unresolved\n&quot;)
  Sys.sleep(0.5)
}
#&gt; while unresolved
#&gt; while unresolved

cat(&quot;Write complete:&quot;, is.null(m$data))
#&gt; Write complete: TRUE
</code></pre>
<p>Now actions which depend on the resolution may be processed, for example the next write.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:example-3-resilient-pipelines">Example 3: Resilient Pipelines</h3>
<p>Use case: isolating code that can potentially fail in a separate process to ensure continued uptime.</p>
<p>As part of a data science / machine learning pipeline, iterations of model training may periodically fail for stochastic and uncontrollable reasons (e.g. buggy memory management on graphics cards).</p>
<p>Running each iteration in a ‘mirai’ isolates this potentially-problematic code such that even if it does fail, it does not bring down the entire pipeline.</p>
<pre><code class="language-r">library(mirai)

run_iteration &lt;- function(i) {

  if (runif(1) &lt; 0.1) stop(&quot;random error\n&quot;, call. = FALSE) # simulates a stochastic error rate
  sprintf(&quot;iteration %d successful\n&quot;, i)

}

for (i in 1:10) {

  m &lt;- mirai(run_iteration(i), environment())
  while (is_error_value(call_mirai(m)$data)) {
    cat(m$data)
    m &lt;- mirai(run_iteration(i), environment())
  }
  cat(m$data)

}
#&gt; iteration 1 successful
#&gt; iteration 2 successful
#&gt; iteration 3 successful
#&gt; iteration 4 successful
#&gt; iteration 5 successful
#&gt; iteration 6 successful
#&gt; Error: random error
#&gt; iteration 7 successful
#&gt; iteration 8 successful
#&gt; iteration 9 successful
#&gt; iteration 10 successful
</code></pre>
<p>Further, by testing the return value of each ‘mirai’ for errors, error-handling code is then able to automate recovery and re-attempts, as in the above example. Further details on <a href="#errors-interrupts-and-timeouts">error handling</a> can be found in the section below.</p>
<p>The end result is a resilient and fault-tolerant pipeline that minimises downtime by eliminating interruptions of long computes.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:daemons-local-persistent-processes">Daemons: Local Persistent Processes</h3>
<p>Daemons, or persistent background processes, may be set to receive ‘mirai’ requests.</p>
<p>This is potentially more efficient as new processes no longer need to be created on an <em>ad hoc</em> basis.</p>
<p>Daemons inherit the default system configuration and read in the relevant ‘.Renviron’ and ‘.Rprofile’ etc. on startup. They also load the default packages. To instead only load the <code>base</code> package (which cuts out more than half of R’s startup time), the environment variable <code>R_SCRIPT_DEFAULT_PACKAGES=NULL</code> may be set prior to launching daemons.</p>
<h4 id="sec:with-dispatcher-default">With Dispatcher (default)</h4>
<p>Call <code>daemons()</code> specifying the number of daemons to launch.</p>
<pre><code class="language-r">daemons(6)
#&gt; [1] 6
</code></pre>
<p>To view the current status, <code>status()</code> provides the number of active connections, the URL daemons connect to, and a named vector showing the number of awaiting, executing and completed tasks:</p>
<ul>
<li><code>waiting</code> number of tasks queued for execution at dispatcher</li>
<li><code>assigned</code> number of tasks sent to a daemon for execution</li>
<li><code>complete</code> number of tasks for which the result has been received (either completed or cancelled)</li>
</ul>
<pre><code class="language-r">status()
#&gt; $connections
#&gt; [1] 6
#&gt; 
#&gt; $daemons
#&gt; [1] &quot;abstract://61f3b00995a8c1e081a9fb98&quot;
#&gt; 
#&gt; $mirai
#&gt;  awaiting executing completed 
#&gt;         0         0         0
</code></pre>
<p>The default <code>dispatcher = TRUE</code> creates a <code>dispatcher()</code> background process that connects to individual daemon processes on the local machine. This ensures that tasks are dispatched efficiently on a first-in first-out (FIFO) basis to daemons for processing. Tasks are queued at dispatcher and sent to a daemon as soon as it can accept the task for immediate execution.</p>
<p>Dispatcher uses synchronisation primitives from <a href="https://doi.org/10.5281/zenodo.7903429"><code>nanonext</code></a>, waiting upon rather than polling at intervals for tasks, which is efficient both in terms of consuming no resources while waiting, and also being fully synchronised with events (having no latency).</p>
<pre><code class="language-r">daemons(0)
#&gt; [1] 0
</code></pre>
<p>Set the number of daemons to zero to reset. This reverts to the default of creating a new background process for each ‘mirai’ request.</p>
<h4 id="sec:without-dispatcher">Without Dispatcher</h4>
<p>Alternatively, specifying <code>dispatcher = FALSE</code>, the background daemons connect directly to the host process.</p>
<pre><code class="language-r">daemons(6, dispatcher = FALSE)
#&gt; [1] 6
</code></pre>
<p>Requesting the status now shows 6 connections, along with the host URL at <code>$daemons</code>.</p>
<pre><code class="language-r">status()
#&gt; $connections
#&gt; [1] 6
#&gt; 
#&gt; $daemons
#&gt; [1] &quot;abstract://c910c5fc17b314069fe962e6&quot;
</code></pre>
<p>This implementation sends tasks immediately, and ensures that tasks are evenly-distributed amongst daemons. This means that optimal scheduling is not guaranteed as the duration of tasks cannot be known <em>a priori</em>. As an example, tasks could be queued at a daemon behind a long-running task, whilst other daemons are idle having already completed their tasks.</p>
<p>The advantage of this approach is that it is low-level and does not require an additional dispatcher process. It is well-suited to working with similar-length tasks, or where the number of concurrent tasks typically does not exceed available daemons.</p>
<h4 id="sec:everywhere">Everywhere</h4>
<p><code>everywhere()</code> may be used to evaluate an expression on all connected daemons and persist the resultant state, regardless of a daemon’s ‘cleanup’ setting.</p>
<pre><code class="language-r">everywhere(library(DBI))
</code></pre>
<p>The above keeps the <a href="https://dbi.r-dbi.org/"><code>DBI</code></a> package loaded for all evaluations. Other types of setup task may also be performed, including making a common resource available, such as a database connection:</p>
<pre><code class="language-r">file &lt;- tempfile()
everywhere(con &lt;&lt;- dbConnect(RSQLite::SQLite(), file), file = file)
</code></pre>
<p>By super-assignment, the conenction ‘con’ will be available in the global environment of all daemon instances. Subsequent mirai calls may then make use of ‘con’.</p>
<pre><code class="language-r">m &lt;- mirai(capture.output(str(con)))
m[]
#&gt; [1] &quot;Formal class 'SQLiteConnection' [package \&quot;RSQLite\&quot;] with 8 slots&quot;  
#&gt; [2] &quot;  ..@ ptr                :&lt;externalptr&gt; &quot;                            
#&gt; [3] &quot;  ..@ dbname             : chr \&quot;/tmp/RtmpBA6yAD/file17a914db50cf1\&quot;&quot;
#&gt; [4] &quot;  ..@ loadable.extensions: logi TRUE&quot;                                
#&gt; [5] &quot;  ..@ flags              : int 70&quot;                                   
#&gt; [6] &quot;  ..@ vfs                : chr \&quot;\&quot;&quot;                                 
#&gt; [7] &quot;  ..@ ref                :&lt;environment: 0x5661b9d35fa8&gt; &quot;            
#&gt; [8] &quot;  ..@ bigint             : chr \&quot;integer64\&quot;&quot;                        
#&gt; [9] &quot;  ..@ extended_types     : logi FALSE&quot;
</code></pre>
<p>Disconnect from the database everywhere, and set the number of daemons to zero to reset.</p>
<pre><code class="language-r">everywhere(dbDisconnect(con))

daemons(0)
#&gt; [1] 0
</code></pre>
<h4 id="sec:with-method">With Method</h4>
<p><code>daemons()</code> has a <code>with()</code> method, which evaluates an expression with daemons created for the duration of the expression and automatically torn down upon completion. It was designed for the use case of running a Shiny app with the desired number of daemons.</p>
<pre><code class="language-r">with(daemons(4), shiny::runApp(app))
</code></pre>
<p>Note: in the above case, it is assumed the app is already created. Wrapping a call to <code>shiny::shinyApp()</code> would not work as <code>runApp()</code> is implicitly called when the app is printed, however printing occurs only after <code>with()</code> has returned, hence the app would run outside of the scope of the <code>with()</code> statement.</p>
<p>In the case of a Shiny app, all mirai calls will be executed before the app returns. In the case of other expressions, be sure to call the results (or collect the values) of all mirai within the expression so that daemons are not reset before they have all completed.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:distributed-computing-remote-daemons">Distributed Computing: Remote Daemons</h3>
<p>The daemons interface may also be used to send tasks for computation to remote daemon processes on the network.</p>
<p>Call <code>daemons()</code> specifying ‘url’ as a character string such as: ‘tcp://10.75.32.70:5555’ at which daemon processes should connect to. Alternatively, use <code>host_url()</code> to automatically construct a valid URL. The host / dispatcher listens at this address, utilising a single port.</p>
<p>IPv6 addresses are also supported and must be enclosed in square brackets <code>[]</code> to avoid confusion with the final colon separating the port. For example, port 5555 on the IPv6 address <code>::ffff:a6f:50d</code> would be specified as <code>tcp://[::ffff:a6f:50d]:5555</code>.</p>
<p>For options on actually launching the daemons, please see the next section.</p>
<p>Below, calling <code>host_url()</code> without a port value uses the default of ‘0’. This is a wildcard value that will automatically cause a free ephemeral port to be assigned:</p>
<pre><code class="language-r">daemons(url = host_url())
#&gt; [1] 0
</code></pre>
<p>The actual assigned port may be queried at any time via <code>status()</code>:</p>
<pre><code class="language-r">status()
#&gt; $connections
#&gt; [1] 0
#&gt; 
#&gt; $daemons
#&gt; [1] &quot;tcp://hostname:34711&quot;
#&gt; 
#&gt; $mirai
#&gt;  awaiting executing completed 
#&gt;         0         0         0
</code></pre>
<p>Dispatcher automatically adjusts to the number of daemons actually connected. Hence it is possible to dynamically scale up or down the number of daemons according to requirements.</p>
<p>To reset all connections and revert to default behaviour:</p>
<pre><code class="language-r">daemons(0)
#&gt; [1] 0
</code></pre>
<p>Closing the connection causes the dispatcher to exit automatically, and in turn all connected daemons when their respective connections with the dispatcher are terminated.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:distributed-computing-launching-daemons">Distributed Computing: Launching Daemons</h3>
<p>To launch remote daemons, supply a remote launch configuration to the ‘remote’ argument of <code>daemons()</code> when setting up daemons, or <code>launch_remote()</code> at any time afterwards.</p>
<p><code>ssh_config()</code> may be used to generate a remote launch configuration if there is SSH access to the remote machine, or else <code>remote_config()</code> provides a flexible method for generating a configuration involving a custom resource manager / application.</p>
<h4 id="sec:ssh-direct-connection">SSH Direct Connection</h4>
<p>The first example below launches 4 daemons on the machine 10.75.32.90 (using the default SSH port of 22 as this was not specified), connecting back to the dispatcher URLs:</p>
<pre><code class="language-r">daemons(
  n = 4L,
  url = host_url(port = 5555),
  remote = ssh_config(remotes = &quot;ssh://10.75.32.90&quot;)
)
</code></pre>
<p>The second example below launches one daemon on each of 10.75.32.90 and 10.75.32.91 using the custom SSH port of 222:</p>
<pre><code class="language-r">daemons(
  n = 1L,
  url = host_url(port = 5555),
  remote = ssh_config(c(&quot;ssh://10.75.32.90:222&quot;, &quot;ssh://10.75.32.91:222&quot;))
)
</code></pre>
<p>In the above examples, as the remote daemons connect back directly, port 5555 on the local machine must be open to incoming connections from the remote addresses.</p>
<h4 id="sec:ssh-tunnelling">SSH Tunnelling</h4>
<p>Use of SSH tunnelling provides a convenient way to launch remote daemons without requiring the remote machine to be able to access the host. Often firewall configurations or security policies may prevent opening a port to accept outside connections.</p>
<p>In these cases SSH tunnelling offers a solution by creating a tunnel once the initial SSH connection is made. For simplicity, this SSH tunnelling implementation uses the same port on both the side of the host and that of the corresponding node. SSH key-based authentication must also already be in place.</p>
<p>Tunnelling requires the hostname for ‘url’ specified when setting up daemons to be ‘127.0.0.1’. This is as the tunnel is created between 127.0.0.1:port on each machine. The host listens to its 127.0.0.1:port and the remotes each dial into 127.0.0.1:port on their own respective machines.</p>
<p>The below example launches 2 nodes on the remote machine 10.75.32.90 using SSH tunnelling over port 5555 (‘url’ hostname is specified as ‘127.0.0.1’):</p>
<pre><code class="language-r">daemons(
  n = 1L,
  url = &quot;tcp://127.0.0.1:5555&quot;,
  remote = ssh_config(
    remotes = c(&quot;ssh://10.75.32.90&quot;, &quot;ssh://10.75.32.90&quot;),
    port = 5555,
    tunnel = TRUE
  )
)
</code></pre>
<h4 id="sec:cluster-resource-managers">Cluster Resource Managers</h4>
<p><code>remote_config()</code> may be used to run a command to deploy daemons using a resource manager.</p>
<p>Taking Slurm as an example, the following uses <code>sbatch</code> to launch a daemon on the cluster, with some additional arguments to <code>sbatch</code> specifying the resource allocation:</p>
<pre><code class="language-r">daemons(
  n = 2,
  url = host_url(),
  remote = remote_config(
    command = &quot;sbatch&quot;,
    args = c(&quot;--mem 512&quot;, &quot;-n 1&quot;, &quot;--wrap&quot;, &quot;.&quot;),
    rscript = file.path(R.home(&quot;bin&quot;), &quot;Rscript&quot;),
    quote = TRUE
  )
)
</code></pre>
<h4 id="sec:manual-deployment">Manual Deployment</h4>
<p>As an alternative to automated launches, calling <code>launch_remote()</code> without specifying ‘remote’ may be used to return the shell commands for deploying daemons manually. The printed return values may be copy / pasted directly to a remote machine.</p>
<pre><code class="language-r">daemons(url = host_url())
#&gt; [1] 0
launch_remote(2)
#&gt; [1]
#&gt; Rscript -e 'mirai::daemon(&quot;tcp://hostname:34495&quot;,rs=c(10407,-1548736186,795843343,1112403460,-75379403,-879623054,1922652491),dispatcher=TRUE)'
#&gt; 
#&gt; [2]
#&gt; Rscript -e 'mirai::daemon(&quot;tcp://hostname:34495&quot;,rs=c(10407,177393518,-240118901,227679337,1647891508,-951127399,-86322505),dispatcher=TRUE)'
daemons(0)
#&gt; [1] 0
</code></pre>
<p>Note that <code>daemons()</code> should be set up on the host machine before launching <code>daemon()</code> on remote resources, otherwise the daemon instances will exit if a connection is not immediately available. Alternatively, specifying the argument <code>autoexit = FALSE</code> will allow daemons to wait (indefinitely) for a connection to become available.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:distributed-computing-tls-secure-connections">Distributed Computing: TLS Secure Connections</h3>
<p>TLS is available as an option to secure communications from the local machine to remote daemons.</p>
<h4 id="sec:zero-configuration">Zero-configuration</h4>
<p>An automatic zero-configuration default is implemented. Simply specify a secure URL using the scheme <code>tls+tcp://</code> when setting daemons, or use <code>host_url(tls = TRUE)</code>, for example:</p>
<pre><code class="language-r">daemons(url = host_url(tls = TRUE))
#&gt; [1] 0
</code></pre>
<p>Single-use keys and certificates are automatically generated and configured, without requiring any further intervention. The private key is always retained on the host machine and never transmitted.</p>
<p>The generated self-signed certificate is available via <code>launch_remote()</code>. This function conveniently constructs the full shell command to launch a daemon, including the correctly specified ‘tls’ argument to <code>daemon()</code>.</p>
<pre><code class="language-r">launch_remote(1)
#&gt; [1]
#&gt; Rscript -e 'mirai::daemon(&quot;tls+tcp://hostname:46223&quot;,tls=c(&quot;-----BEGIN CERTIFICATE-----
#&gt; MIIFNzCCAx+gAwIBAgIBATANBgkqhkiG9w0BAQsFADAzMREwDwYDVQQDDAhrdW1h
#&gt; bW90bzERMA8GA1UECgwITmFub25leHQxCzAJBgNVBAYTAkpQMB4XDTAxMDEwMTAw
#&gt; MDAwMFoXDTMwMTIzMTIzNTk1OVowMzERMA8GA1UEAwwIa3VtYW1vdG8xETAPBgNV
#&gt; BAoMCE5hbm9uZXh0MQswCQYDVQQGEwJKUDCCAiIwDQYJKoZIhvcNAQEBBQADggIP
#&gt; ADCCAgoCggIBAK3MYDqsrXgGMed15Jv5NkxDqpxssmEsUkm74YA4/ocUBFpmVaGL
#&gt; 7NyKwRJFHxZHzHCjJ4jwRcfvgVs3VtZJZfbziFqfoVwO4Yw4o7I+2RVJx8vobTts
#&gt; RSxRkERhZ7AQSYR7c8+GzsjtoRQc7f6c6BkfoRiDOmg5g8QjbB12wBRHe6e+t0jT
#&gt; SKNqPSsuVl4wBHU3pDGEiHKHprc7dyObGOhGRVzQ+tpqS2Jrwo4HZCugsWSQRYWZ
#&gt; EBOQJ5Z5U4eMr6TcgcvdxCn8Y2cAkOKQgaCcrt/1o+shbfnruwUSgziDwnD3SCqQ
#&gt; KCIapKs4oJBe/vYg8SMG+HiNqXZKuJzD/FJNSEDZrF/lszMwly5pbobNfQpkgTTk
#&gt; w7eIiy6ZWCF60FFT49StigjmQV32/KkQrhiQGW0av1ExakQt9FNuWAxG2oFs/uKF
#&gt; HZN6Cmr7zWYRTmNmLQlhvsM7Ck+AQjvZ7UqmPXGBe9KNvpRGtqm+4UgFumvWc+sv
#&gt; 3EDMlB6tcg1uspJuyYr6PZ3NpUDgxHNsNXPmk4lb/ywU0SBRvxeASwXQIw3CJTiw
#&gt; PV5KyDSw51HYMOYjKAtJjtEtXuKCxOTwAmUM6gMDrbhIsQg4ys2yOVHhEefqEijP
#&gt; iKizrQt0tCQXIBHGHkdO6DBrrK0JEhYBfBDTrz1PFU+83ymLwrPLgAtrAgMBAAGj
#&gt; VjBUMBIGA1UdEwEB/wQIMAYBAf8CAQAwHQYDVR0OBBYEFJePaxpbycudDyQm/v3f
#&gt; utWSDH6xMB8GA1UdIwQYMBaAFJePaxpbycudDyQm/v3futWSDH6xMA0GCSqGSIb3
#&gt; DQEBCwUAA4ICAQAYLPcaDAS3juvwNDvzcZ9xTVtNZpCZ3m3vzoRXGQtIccs6oZ7p
#&gt; f/1cqTaPkUxYo0KQsnXJLdqE6wG5qy3FlbAH8XKH4Q63uYLkED9Y2JbnhQaujhvP
#&gt; 2V/QQHe9a2NH9/NDr2WRJMxxoy0ublSe+kTMdQjajsgHZczz19okPB9cdPvI1bYH
#&gt; K4hpb1/s6rBOd0JsymqajKmv44F2AXYKgBE2G83BdhdXf/7a430T9KmnOsi5q+sZ
#&gt; b1Bdjn8ajHxxCfTpudTvxe4E7X9YA1d2bsX46rl6ap5zKoerSbBZRFBE2DgupegM
#&gt; yKBRYypCFLSiRW4zQX+AlVlKgudSG4rPuniJwUDitt06CTxUJnKo04FyUKJVq0tl
#&gt; kOvvGKh2kHO2i0FGbZf/pozwe5HAdvcP2WMEIH16ikoHzDmIMKg0drhJBrNfz0wC
#&gt; EEXtaMQQu7dOcvQvkud0BXJQqk6NXM6PyqGUc1VgtWnKYjUC4+XB3EBCTdYR922V
#&gt; PBtGDEvis0NzvrF++dGWKnACK7Z6VE2U/flmj4TRTLHYj14MVAcNopN/aV7aEp3P
#&gt; yVcLzpj+Cnm4rWrKjTrLihH2+/0O5PCQy5VutXcjOMA2tqilE706Kl6IMXDt7eLF
#&gt; 4DfVuE/NpVL7gDfvlRSg2vvmgSj5zzC7NFOVcU5fyRUHg3mI3TvPZONfwg==
#&gt; -----END CERTIFICATE-----
#&gt; &quot;,&quot;&quot;),rs=c(10407,-1811307506,-1390734025,335202316,-2079928931,-545218630,567695859),dispatcher=TRUE)'
</code></pre>
<p>The printed value may be deployed directly on a remote machine.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h4 id="sec:ca-signed-certificates">CA Signed Certificates</h4>
<p>As an alternative to the zero-configuration default, a certificate may also be generated via a Certificate Signing Request (CSR) to a Certificate Authority (CA), which may be a public CA or a CA internal to an organisation.</p>
<ol>
<li>Generate a private key and CSR. The following resources describe how to do so:</li>
</ol>
<ul>
<li>using Mbed TLS: <a href="https://mbed-tls.readthedocs.io/en/latest/kb/how-to/generate-a-certificate-request-csr/">https://mbed-tls.readthedocs.io/en/latest/kb/how-to/generate-a-certificate-request-csr/</a></li>
<li>using OpenSSL: <a href="https://www.feistyduck.com/library/openssl-cookbook/online/">https://www.feistyduck.com/library/openssl-cookbook/online/</a> (Chapter 1.2 Key and Certificate Management)</li>
</ul>
<ol start="2">
<li>Provide the generated CSR to the CA for it to sign a new TLS certificate.</li>
</ol>
<ul>
<li>The common name (CN) of the certificate must be identical to the hostname or IP address actually used for the connection. As this is verified, it will fail if not the same.</li>
<li>The received certificate should comprise a block of cipher text between the markers <code>-----BEGIN CERTIFICATE-----</code> and <code>-----END CERTIFICATE-----</code>. Make sure to request the certificate in the PEM format. If only available in other formats, the TLS library used should usually provide conversion utilities.</li>
<li>Check also that the private key is a block of cipher text between the markers <code>-----BEGIN PRIVATE KEY-----</code> and <code>-----END PRIVATE KEY-----</code>.</li>
</ul>
<ol start="3">
<li>When setting daemons, the TLS certificate and private key should be provided to the ‘tls’ argument of <code>daemons()</code>.</li>
</ol>
<ul>
<li>If the certificate and private key have been imported as character strings <code>cert</code> and <code>key</code> respectively, then the ‘tls’ argument may be specified as the character vector <code>c(cert, key)</code>.</li>
<li>Alternatively, the certificate may be copied to a new text file, with the private key appended, in which case the path/filename of this file may be provided to the ‘tls’ argument.</li>
</ul>
<ol start="4">
<li>When launching daemons, the certificate chain to the CA should be supplied to the ‘tls’ argument of <code>daemon()</code> or <code>launch_remote()</code>.</li>
</ol>
<ul>
<li>The certificate chain should comprise multiple certificates, each between <code>-----BEGIN CERTIFICATE-----</code> and <code>-----END CERTIFICATE-----</code> markers. The first one should be the newly-generated TLS certificate, the same supplied to <code>daemons()</code>, and the final one should be a CA root certificate.</li>
<li>These are the only certificates required if the certificate was signed directly by a CA. If not, then the intermediate certificates should be included in a certificate chain that starts with the TLS certificate and ends with the certificate of the CA.</li>
<li>If these are concatenated together as a single character string <code>certchain</code>, then the character vector comprising this and an empty character string <code>c(certchain, &quot;&quot;)</code> may be supplied to the relevant ‘tls’ argument.</li>
<li>Alternatively, if these are written to a file (and the file replicated on the remote machines), then the ‘tls’ argument may also be specified as a path/filename (assuming these are the same on each machine).</li>
</ul>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:compute-profiles">Compute Profiles</h3>
<p>The <code>daemons()</code> interface also allows the specification of compute profiles for managing tasks with heterogeneous compute requirements:</p>
<ul>
<li>send tasks to different daemons or clusters of daemons with the appropriate specifications (in terms of CPUs / memory / GPU / accelerators etc.)</li>
<li>split tasks between local and remote computation</li>
</ul>
<p>Simply specify the argument <code>.compute</code> when calling <code>daemons()</code> with a profile name (which is ‘default’ for the default profile). The daemons settings are saved under the named profile.</p>
<p>To create a ‘mirai’ task using a specific compute profile, specify the ‘.compute’ argument to <code>mirai()</code>, which defaults to the ‘default’ compute profile.</p>
<p>Similarly, functions such as <code>status()</code>, <code>launch_local()</code> or <code>launch_remote()</code> should be specified with the desired ‘.compute’ argument.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:errors-interrupts-and-timeouts">Errors, Interrupts and Timeouts</h3>
<p>If execution in a mirai fails, the error message is returned as a character string of class ‘miraiError’ and ‘errorValue’ to facilitate debugging. <code>is_mirai_error()</code> may be used to test for mirai execution errors.</p>
<pre><code class="language-r">m1 &lt;- mirai(stop(&quot;occurred with a custom message&quot;, call. = FALSE))
m1[]
#&gt; 'miraiError' chr Error: occurred with a custom message

m2 &lt;- mirai(mirai::mirai())
m2[]
#&gt; 'miraiError' chr Error in mirai::mirai(): missing expression, perhaps wrap in {}?

is_mirai_error(m2$data)
#&gt; [1] TRUE
is_error_value(m2$data)
#&gt; [1] TRUE
</code></pre>
<p>A full stack trace of evaluation within the mirai is recorded and accessible at <code>$stack.trace</code> on the error object.</p>
<pre><code class="language-r">f &lt;- function(x) if (x &gt; 0) stop(&quot;positive&quot;)

m3 &lt;- mirai({f(-1); f(1)}, f = f)
m3[]
#&gt; 'miraiError' chr Error in f(1): positive

m3$data$stack.trace
#&gt; [[1]]
#&gt; [1] &quot;stop(\&quot;positive\&quot;)&quot;
#&gt; 
#&gt; [[2]]
#&gt; [1] &quot;f(1)&quot;
</code></pre>
<p>Elements of the original error condition are also accessible via <code>$</code> on the error object. For example, additional metadata recorded by <code>rlang::abort()</code> is preserved:</p>
<pre><code class="language-r">f &lt;- function(x) if (x &gt; 0) stop(&quot;positive&quot;)

m4 &lt;- mirai(rlang::abort(&quot;aborted&quot;, meta_uid = &quot;UID001&quot;))
m4[]
#&gt; 'miraiError' chr Error: aborted

m4$data$meta_uid
#&gt; [1] &quot;UID001&quot;
</code></pre>
<p>If a daemon instance is sent a user interrupt, the mirai will resolve to an object of class ‘miraiInterrupt’ and ‘errorValue’. <code>is_mirai_interrupt()</code> may be used to test for such interrupts.</p>
<pre><code class="language-r">m4 &lt;- mirai(rlang::interrupt()) # simulates a user interrupt
is_mirai_interrupt(m4[])
#&gt; [1] TRUE
</code></pre>
<p>If execution of a mirai surpasses the timeout set via the ‘.timeout’ argument, the mirai will resolve to an ‘errorValue’ of 5L (timed out). This can, amongst other things, guard against mirai processes that have the potential to hang and never return.</p>
<pre><code class="language-r">m5 &lt;- mirai(nanonext::msleep(1000), .timeout = 500)
m5[]
#&gt; 'errorValue' int 5 | Timed out

is_mirai_error(m5$data)
#&gt; [1] FALSE
is_mirai_interrupt(m5$data)
#&gt; [1] FALSE
is_error_value(m5$data)
#&gt; [1] TRUE
</code></pre>
<p><code>is_error_value()</code> tests for all mirai execution errors, user interrupts and timeouts.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:serialization-arrow-polars-and-beyond">Serialization: Arrow, polars and beyond</h3>
<p>Native R serialization is used for sending data between host and daemons. Some R objects by their nature cannot be serialized, such as those accessed via an external pointer. In these cases, performing ‘mirai’ operations on them would normally error.</p>
<p>Using the <a href="https://arrow.apache.org/docs/r/"><code>arrow</code></a> package as an example:</p>
<pre><code class="language-r">library(arrow, warn.conflicts = FALSE)
daemons(1)
#&gt; [1] 1
everywhere(library(arrow))

x &lt;- as_arrow_table(iris)

m &lt;- mirai(list(a = head(x), b = &quot;some text&quot;), x = x)
m[]
#&gt; 'miraiError' chr Error: Invalid &lt;Table&gt;, external pointer to null
</code></pre>
<p>However, <code>serial_config()</code> can be used to create custom serialization configurations, specifying functions that hook into R’s native serialization mechanism for reference objects (‘refhooks’).</p>
<p>This configuration may then be passed to the ‘serial’ argument of a <code>daemons()</code> call.</p>
<pre><code class="language-r">cfg &lt;- serial_config(
  class = &quot;ArrowTabular&quot;,
  sfunc = arrow::write_to_raw,
  ufunc = function(x) arrow::read_ipc_stream(x, as_data_frame = FALSE)
)

daemons(1, serial = cfg)
#&gt; [1] 1

everywhere(library(arrow))

m &lt;- mirai(list(a = head(x), b = &quot;some text&quot;), x = x)
m[]
#&gt; $a
#&gt; Table
#&gt; 6 rows x 5 columns
#&gt; $Sepal.Length &lt;double&gt;
#&gt; $Sepal.Width &lt;double&gt;
#&gt; $Petal.Length &lt;double&gt;
#&gt; $Petal.Width &lt;double&gt;
#&gt; $Species &lt;dictionary&lt;values=string, indices=int8&gt;&gt;
#&gt; 
#&gt; See $metadata for additional Schema metadata
#&gt; 
#&gt; $b
#&gt; [1] &quot;some text&quot;

daemons(0)
#&gt; [1] 0
</code></pre>
<p>It can be seen that this time, the arrow table is seamlessly handled in the ‘mirai’ process. This is the case even when the object is deeply nested inside lists or other structures.</p>
<p>Different serialization functions may be registered for different compute profiles. As an example, the ‘polars’ profile can be set up to use <a href="https://pola-rs.github.io/r-polars/"><code>polars</code></a>, a ‘lightning fast’ dataframe library written in Rust (requires <code>polars</code> &gt;= 0.16.4).</p>
<pre><code class="language-r">daemons(
  n = 1,
  serial = serial_config(
    class = &quot;RPolarsDataFrame&quot;,
    sfunc = function(x) polars::as_polars_df(x)$to_raw_ipc(),
    ufunc = polars::pl$read_ipc
  ),
  .compute = &quot;polars&quot;
)
#&gt; [1] 1

x &lt;- polars::as_polars_df(iris)

m &lt;- mirai(list(a = head(x), b = &quot;some text&quot;), x = x, .compute = &quot;polars&quot;)
m[]
#&gt; $a
#&gt; shape: (6, 5)
#&gt; ┌──────────────┬─────────────┬──────────────┬─────────────┬─────────┐
#&gt; │ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species │
#&gt; │ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     │
#&gt; │ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat     │
#&gt; ╞══════════════╪═════════════╪══════════════╪═════════════╪═════════╡
#&gt; │ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa  │
#&gt; │ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa  │
#&gt; │ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa  │
#&gt; │ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         ┆ setosa  │
#&gt; │ 5.0          ┆ 3.6         ┆ 1.4          ┆ 0.2         ┆ setosa  │
#&gt; │ 5.4          ┆ 3.9         ┆ 1.7          ┆ 0.4         ┆ setosa  │
#&gt; └──────────────┴─────────────┴──────────────┴─────────────┴─────────┘
#&gt; 
#&gt; $b
#&gt; [1] &quot;some text&quot;

daemons(0, .compute = &quot;polars&quot;)
#&gt; [1] 0
</code></pre>
<p>The ‘vec’ argument to <code>serialization()</code> may be specified as <code>TRUE</code> if the serialization functions are vectorized and take lists of objects, as is the case for <a href="https://mlverse.github.io/safetensors/"><code>safetensors</code></a>, used for serialization in <a href="https://torch.mlverse.org/"><code>torch</code></a>.</p>
<p>Please refer to the <a href="https://shikokuchuo.net/mirai/articles/torch.html">torch vignette</a> for further examples.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:asynchronous-parallel-map">Asynchronous Parallel Map</h3>
<p><code>mirai_map()</code> performs asynchronous parallel/distributed map using <code>mirai</code>.</p>
<p>This function is similar to <code>purrr::map()</code>, but returns a ‘mirai_map’ object. It is also more advanced as it allows multiple map over the rows of a dataframe or matrix.</p>
<p>The results of a mirai_map <code>x</code> may be collected using <code>x[]</code>. This waits for all asynchronous operations to complete if still in progress.</p>
<h4 id="sec:key-advantages">Key advantages:</h4>
<ol>
<li>Returns immediately with all evaluations taking place asynchronously. Printing a ‘mirai map’ object shows the current completion progress.</li>
<li>The ‘.promise’ argument allows a promise to registered against each mirai, which can be used to perform side-effects.</li>
<li>Returns evaluation errors as ‘miraiError’ or ‘errorValue’ as the case may be, rather than causing the entire operation to fail. This allows more efficient recovery from partial failure.</li>
<li>Does not rely on a ‘chunking’ algorithm that attempts to split work into batches according to the number of available daemons, as implemented for example in the <code>parallel</code> package. Chunking cannot take into account varying or unpredictable compute times over the indices. It can be optimal to rely on <code>mirai</code> for scheduling instead. This is demonstrated in the example below.</li>
</ol>
<pre><code class="language-r">library(mirai)
library(parallel)
cl &lt;- make_cluster(4)
daemons(4)
#&gt; [1] 4
vec &lt;- c(1, 1, 4, 4, 1, 1, 1, 1)
system.time(mirai_map(vec, Sys.sleep)[])
#&gt;    user  system elapsed 
#&gt;   0.001   0.004   4.006
system.time(parLapply(cl, vec, Sys.sleep))
#&gt;    user  system elapsed 
#&gt;   0.016   0.077   8.091
</code></pre>
<p><code>.args</code> is used to specify further constant arguments to <code>.f</code> - the ‘mean’ and ‘sd’ in the example below:</p>
<pre><code class="language-r">with(
  daemons(3, dispatcher = FALSE),
  mirai_map(1:3, rnorm, .args = list(mean = 20, sd = 2))[]
)
#&gt; [[1]]
#&gt; [1] 21.67525
#&gt; 
#&gt; [[2]]
#&gt; [1] 20.10329 19.76841
#&gt; 
#&gt; [[3]]
#&gt; [1] 20.36542 20.73644 19.38807
</code></pre>
<p>Use <code>...</code> to further specify objects referenced but not defined in <code>.f</code> - the ‘do’ in the anonymous function below:</p>
<pre><code class="language-r">ml &lt;- mirai_map(
  c(a = 1, b = 2, c = 3),
  function(x) do(x, as.logical(x %% 2)),
  do = nanonext::random
)
#&gt; Warning: mirai is launching one local daemon for a map operation as none previously set
ml
#&gt; &lt; mirai map [1/3] &gt;
ml[]
#&gt; $a
#&gt; [1] &quot;47&quot;
#&gt; 
#&gt; $b
#&gt; [1] f4 de
#&gt; 
#&gt; $c
#&gt; [1] &quot;9accab&quot;
</code></pre>
<p>Use of <code>mirai_map()</code> assumes that <code>daemons()</code> have previously been set. If not then one (non-dispatcher) daemon is set to allow the function to proceed. This ensures safe behaviour, but is unlikely to be optimal, so please ensure daemons are set beforehand.</p>
<h4 id="sec:collecting-results">Collecting Results</h4>
<p>When collecting the results, optionally specify arguments to <code>[]</code>:</p>
<ul>
<li><code>x[.flat]</code> collects and flattens the results, checking that they are of the same type to avoid coercion.</li>
<li><code>x[.progress]</code> collects results using a <code>cli</code> progress bar, if available, showing completion percentage and ETA, or else a simple text progress indicator of parts completed of the total. If the map operation completes quickly, the <code>cli</code> progress bar may not show at all, and this is by design.</li>
<li><code>x[.stop]</code> collects the results applying early stopping, which stops at the first failure and cancels remaining computations. If the <code>cli</code> package is available, it will be used for displaying the error message.</li>
</ul>
<p>Combinations of the above may be supplied in the fashion of <code>x[.stop, .progress]</code>.</p>
<pre><code class="language-r">mirai_map(list(a = 1, b = &quot;a&quot;, c = 3), sum)[.stop]
#&gt; Error in `mirai::mirai_map()`:
#&gt; ℹ In index 2.
#&gt; ✖ Error in .Primitive(&quot;sum&quot;)(&quot;a&quot;): invalid 'type' (character) of argument

with(
  daemons(4, dispatcher = FALSE),
  mirai_map(c(0.1, 0.2, 0.3), Sys.sleep)[.progress, .flat]
)
#&gt; NULL
</code></pre>
<h4 id="sec:multiple-map">Multiple Map</h4>
<p>Multiple map is performed over the <strong>rows</strong> of a dataframe or matrix, as this is most often the desired behaviour.</p>
<p>This allows map over 2 or more arguments by specifying a dataframe. One of those may be an index value for indexed map.</p>
<p>The function <code>.f</code> must take as many arguments as there are columns, either explicitly or via <code>...</code>.</p>
<pre><code class="language-r">fruit &lt;- c(&quot;melon&quot;, &quot;grapes&quot;, &quot;coconut&quot;)

# create a dataframe for indexed map:
df &lt;- data.frame(i = seq_along(fruit), fruit = fruit)

with(
  daemons(3, dispatcher = FALSE),
  mirai_map(df, sprintf, .args = list(fmt = &quot;%d. %s&quot;))[.flat]
)
#&gt; [1] &quot;1. melon&quot;   &quot;2. grapes&quot;  &quot;3. coconut&quot;
</code></pre>
<p>As a dataframe often contains columns of differing type, it is unusual to want to map over the <strong>columns</strong>, however this is possible by simply transforming it beforehand into a list using <code>as.list()</code>.</p>
<p>Similarly, the behaviour of <code>lapply()</code> or <code>purrr::map()</code> on a matrix is the same as that for a vector. <code>mirai_map()</code> on the other hand does take into account the fact that the matrix has dimensions, and maps over its <strong>rows</strong>, consistent with the behaviour for dataframes. If instead, mapping over the columns is desired, simply take the transpose of the matrix beforehand using <code>t()</code>.</p>
<p><a href="#table-of-contents">« Back to ToC</a></p>
<h3 id="sec:using-mirai-in-a-package">Using mirai in a Package</h3>
<p>mirai as a framework is designed to support completely transparent and inter-operable use within packages. A core design precept of not relying on global options or environment variables minimises the likelihood of conflict between use by different packages.</p>
<p>There are hence few requirements of package authors.</p>
<p>The following points may, however, be useful:</p>
<ul>
<li>
<p><code>daemons()</code> settings should usually be left to end-users. Users may be guided to mirai documentation if desired. If however, a package wishes to set default settings, for example, <code>daemons()</code> should always be called specifying <code>force = FALSE</code>. This ensures that any prior user settings are respected, and that daemons set elsewhere are not prematurely terminated.</p>
</li>
<li>
<p>Calling package functions in a mirai requires namespacing the call, or alternatively exporting the function, i.e.</p>
</li>
</ul>
<pre><code class="language-r"> mirai(mypkg::my_func())
</code></pre>
<p>or</p>
<pre><code class="language-r"> mirai(my_func(), .args = list(myfunc = myfunc))
</code></pre>
<ul>
<li>
<p>The shape and contents of a <code>status()</code> call must not be relied upon, as this user interface is subject to change at any time. There is a developer interface <code>nextget()</code>, for querying values such as ‘urls’ described in the function documentation. Note: only the specifically-documented values are supported interfaces.</p>
</li>
<li>
<p>This is recommended practice in any case, but especially relevant for package developers: the functions <code>unresolved()</code>, <code>is_error_value()</code>, <code>is_mirai_error()</code>, and <code>is_mirai_interrupt()</code> should be used to test for the relevant state of a mirai or its value. The characteristics of how they are currently implemented, e.g. as a logical NA for an ‘unresolvedValue’, should not be relied upon, as these are subject to change.</p>
</li>
<li>
<p>Testing on CRAN should respect it’s 2-core usage limit. This practically means limiting tests to using one daemon (with <code>dispatcher = FALSE</code>) to ensure that only one additional process is used. Always reset daemons when done and then allow at least a one-second sleep to ensure all background processes have properly exited. These limits apply only to tests run on CRAN machines and not those run elsewhere.</p>
</li>
</ul>
<p><a href="#table-of-contents">« Back to ToC</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js" defer></script>
</body>
</html>
