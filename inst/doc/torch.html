<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="generator" content="litedown 0.6">
<title>mirai - Torch Integration</title>
<style type="text/css">
body {
  font-family: sans-serif;
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 1.5;
}
body, .abstract, code, .footnotes, footer, #refs, .caption { font-size: .9em; }
li li { font-size: .95em; }
ul:has(li > input[type="checkbox"]) { list-style: none; padding-left: 1em; }
*, :before, :after { box-sizing: border-box; }
a { color: steelblue; }
pre, img { max-width: 100%; }
pre { white-space: pre-wrap; word-break: break-word; }
pre code { display: block; padding: 1em; overflow-x: auto; }
code { font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace; }
:not(pre, th) > code, code[class], div > .caption { background: #f8f8f8; }
pre > code:is(:not([class]), .language-plain, .language-none, .plain), .box, .figure, .table { background: inherit; border: 1px solid #eee; }
pre > code {
  &.message { border-color: #9eeaf9; }
  &.warning { background: #fff3cd; border-color: #fff3cd; }
  &.error { background: #f8d7da; border-color: #f8d7da; }
}
.fenced-chunk { border-left: 1px solid #666; }
.code-fence {
  opacity: .4;
  border: 1px dashed #666;
  border-left: 2px solid;
  &:hover { opacity: inherit; }
}
.box, .figure, .table, table { margin: 1em auto; }
div > .caption { padding: 1px 1em; }
.figure { p:has(img, svg), pre:has(svg) { text-align: center; } }
.flex-col { display: flex; justify-content: space-between; }
table {
  &:only-child:not(.table > *) { margin: auto; }
  th, td { padding: 5px; font-variant-numeric: tabular-nums; }
  thead, tfoot, tr:nth-child(even) { background: whitesmoke; }
  thead th { border-bottom: 1px solid #ddd; }
  &:not(.datatable-table) {
    border-top: 1px solid #666;
    border-bottom: 1px solid #666;
  }
}
blockquote {
  color: #666;
  margin: 0;
  padding: 1px 1em;
  border-left: .5em solid #eee;
}
hr, .footnotes::before { border: 1px dashed #ddd; }
.frontmatter { text-align: center; }
#TOC {
  a { text-decoration: none; }
  ul { list-style: none; padding-left: 1em; }
  & > ul { padding: 0; }
  ul ul { border-left: 1px solid lightsteelblue; }
}
.body h2 { border-bottom: 1px solid #666; }
.body .appendix, .appendix ~ h2 { border-bottom-style: dashed; }
.main-number::after { content: "."; }
span[class^="ref-number-"] { font-weight: bold; }
.ref-number-fig::after, .ref-number-tab::after { content: ":"; }
.cross-ref-chp::before { content: "Chapter "; }
.cross-ref-sec::before { content: "Section "; }
.cross-ref-fig::before, .ref-number-fig::before { content: "Figure "; }
.cross-ref-tab::before, .ref-number-tab::before { content: "Table "; }
.cross-ref-eqn::before, .MathJax_ref:has(mjx-mtext > mjx-c + mjx-c)::before { content: "Equation "; }
.abstract, #refs {
  &::before { display: block; margin: 1em auto; font-weight: bold; }
}
.abstract::before { content: "Abstract"; text-align: center; }
#refs::before { content: "Bibliography"; font-size: 1.5em; }
.ref-paren-open::before { content: "("; }
.ref-paren-close::after { content: ")"; }
.ref-semicolon::after { content: "; "; }
.ref-and::after { content: " and "; }
.ref-et-al::after { content: " et al."; font-style: italic; }
.footnote-ref a {
  &::before { content: "["; }
  &::after { content: "]"; }
}
section.footnotes {
  margin-top: 2em;
  &::before { content: ""; display: block; max-width: 20em; }
}
.fade {
  background: repeating-linear-gradient(135deg, white, white 30px, #ddd 32px, #ddd 32px);
  opacity: 0.6;
}

@media print {
  body { max-width: 100%; }
  tr, img { break-inside: avoid; }
}
@media only screen and (min-width: 992px) {
  body:not(.pagesjs) pre:has(.line-numbers):not(:hover) { white-space: pre; }
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@xiee/utils@1.13.61/css/prism-xcode.min.css">
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js" defer></script>
</head>
<body>
<div class="frontmatter">
<div class="title"><h1>mirai - Torch Integration</h1></div>
</div>
<div class="body">
<h3 id="sec:torch-integration">Torch Integration</h3>
<p>Custom serialization functions may be registered to handle external pointer type reference objects.</p>
<p>This allows tensors from the <a href="https://torch.mlverse.org/"><code>torch</code></a> package to be used seamlessly in ‘mirai’ computations.</p>
<h4 id="sec:setup-steps">Setup Steps</h4>
<ol>
<li>Create the serialization configuration, specifying ‘class’ as ‘torch_tensor’ and ‘vec’ as TRUE.</li>
<li>Set up daemons, supplying the configuration to the ‘serial’ argument.</li>
<li>(Optional) Use <code>everywhere()</code> to make the <code>torch</code> package available on all daemons for convenience.</li>
</ol>
<pre><code class="language-r">library(mirai)
library(torch)

cfg &lt;- serial_config(
  class = &quot;torch_tensor&quot;,
  sfunc = torch::torch_serialize,
  ufunc = torch::torch_load,
  vec = TRUE
)

daemons(1, serial = cfg)
#&gt; [1] 1

everywhere(library(torch))
</code></pre>
<h4 id="sec:example-usage">Example Usage</h4>
<p>The below example creates a convolutional neural network using <code>torch::nn_module()</code>.</p>
<p>A set of model parameters is also specified.</p>
<p>The model specification and parameters are then passed to and initialized within a ‘mirai’.</p>
<pre><code class="language-r">model &lt;- nn_module(
  initialize = function(in_size, out_size) {
    self$conv1 &lt;- nn_conv2d(in_size, out_size, 5)
    self$conv2 &lt;- nn_conv2d(in_size, out_size, 5)
  },
  forward = function(x) {
    x &lt;- self$conv1(x)
    x &lt;- nnf_relu(x)
    x &lt;- self$conv2(x)
    x &lt;- nnf_relu(x)
    x
  }
)

params &lt;- list(in_size = 1, out_size = 20)

m &lt;- mirai(do.call(model, params), model = model, params = params)

m[]
#&gt; An `nn_module` containing 1,040 parameters.
#&gt; 
#&gt; ── Modules ────────────────────────────────────────────────────────────────────────────────────────────────────────
#&gt; • conv1: &lt;nn_conv2d&gt; #520 parameters
#&gt; • conv2: &lt;nn_conv2d&gt; #520 parameters
</code></pre>
<p>The returned model is an object containing many tensor elements.</p>
<pre><code class="language-r">m$data$parameters$conv1.weight
#&gt; torch_tensor
#&gt; (1,1,.,.) = 
#&gt;  -0.0744 -0.0110 -0.0537 -0.0237 -0.1781
#&gt;  -0.1662 -0.0952 -0.1977 -0.1710 -0.0747
#&gt;  -0.0216 -0.0314 -0.1124 -0.1277  0.0098
#&gt;   0.1225  0.1188  0.1468  0.1675 -0.1111
#&gt;   0.1517  0.1384  0.1313  0.0376 -0.0254
#&gt; 
#&gt; (2,1,.,.) = 
#&gt;  -0.0459  0.0087 -0.0113 -0.0393 -0.1890
#&gt;   0.0141  0.1516  0.0133  0.0606 -0.1009
#&gt;  -0.0160 -0.1533 -0.0492 -0.0738  0.1385
#&gt;  -0.1819  0.1906  0.0515  0.0980  0.1830
#&gt;  -0.0678  0.1724  0.0914 -0.1575  0.1338
#&gt; 
#&gt; (3,1,.,.) = 
#&gt;  -0.0386  0.0314  0.0473 -0.1881 -0.0848
#&gt;  -0.0805  0.1641 -0.0009 -0.1189  0.1966
#&gt;   0.0166  0.1321  0.0586 -0.0890 -0.0104
#&gt;   0.1341  0.1446 -0.0266  0.1377  0.0130
#&gt;   0.0878 -0.0120  0.1676 -0.0057 -0.0602
#&gt; 
#&gt; (4,1,.,.) = 
#&gt;   0.0808  0.1956  0.0116  0.0120 -0.0445
#&gt;  -0.0620 -0.1917  0.0159 -0.0426  0.1548
#&gt;   0.1291  0.0993 -0.0191  0.1040  0.0930
#&gt;  -0.0752 -0.0272 -0.1484  0.0472 -0.1651
#&gt;   0.1708  0.0247 -0.0511  0.1567 -0.1810
#&gt; 
#&gt; (5,1,.,.) = 
#&gt;   0.1985 -0.0241  0.1558  0.0839  0.1445
#&gt; ... [the output was truncated (use n=-1 to disable)]
#&gt; [ CPUFloatType{20,1,5,5} ][ requires_grad = TRUE ]
</code></pre>
<p>It is usual for model parameters to then be passed to an optimiser.</p>
<p>This can also be initialized within a ‘mirai’ process.</p>
<pre><code class="language-r">optim &lt;- mirai(optim_rmsprop(params = params), params = m$data$parameters)

optim[]
#&gt; &lt;optim_rmsprop&gt;
#&gt;   Inherits from: &lt;torch_optimizer&gt;
#&gt;   Public:
#&gt;     add_param_group: function (param_group) 
#&gt;     clone: function (deep = FALSE) 
#&gt;     defaults: list
#&gt;     initialize: function (params, lr = 0.01, alpha = 0.99, eps = 1e-08, weight_decay = 0, 
#&gt;     load_state_dict: function (state_dict, ..., .refer_to_state_dict = FALSE) 
#&gt;     param_groups: list
#&gt;     state: State, R6
#&gt;     state_dict: function () 
#&gt;     step: function (closure = NULL) 
#&gt;     zero_grad: function () 
#&gt;   Private:
#&gt;     step_helper: function (closure, loop_fun)

daemons(0)
#&gt; [1] 0
</code></pre>
<p>Above, tensors and complex objects containing tensors were passed seamlessly between host and daemon processes, in the same way as any other R object.</p>
<p>The custom serialization in <code>mirai</code> leverages R’s own native ‘refhook’ mechanism to allow such completely transparent usage. Designed to be fast and efficient, data copies are minimised and the ‘official’ serialization methods from the <code>torch</code> package are used directly.</p>
</div>
</body>
</html>
